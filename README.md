1. Project Overview
The project aims to predict whether a crime case will be closed using two different classifiers:
1.	K-Nearest Neighbors (KNN) Classifier
2.	Decision Tree Classifier
We will compare the performance of both models on the same dataset and evaluate them based on accuracy, precision, recall, F1-score, and other metrics.
2. Tools and Libraries
We will use the following Python libraries:
•	Pandas: For data loading and preprocessing.
•	Scikit-learn: For KNN and Decision Tree classifiers.
•	Matplotlib/Seaborn: For visualization.
Summary of Results
•	K-Nearest Neighbors (KNN)
o	Accuracy: KNN Accuracy %
o	Precision, Recall, F1-Score from the classification report.
o	Confusion matrix for visualization.
•	Decision Tree
o	Accuracy: Decision Tree Accuracy %
o	Precision, Recall, F1-Score from the classification report.
o	Confusion matrix and the decision tree visualization.
Key Learnings:
•	KNN: A simple yet effective classifier that works well with smaller datasets. It requires setting the right number of neighbors (k) to achieve good performance.
•	Decision Tree: A highly interpretable model that performs well but can easily overfit. It’s essential to prune the tree by tuning hyperparameters like max_depth to improve its generalization.

